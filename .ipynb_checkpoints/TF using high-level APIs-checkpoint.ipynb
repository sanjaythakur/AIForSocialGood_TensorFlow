{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow has many classic datasets as part of its repository which makes life of kids like us easier. MNIST is no exception. We'll import it's corresponding package. Yay!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the hyper-parameters for our network. The tricks of the trade of setting these is a topic for some other time (lecture, office-hours etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The MNIST dataset has 10 classes, representing the digits 0 through 9.\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# The MNIST images are always 28x28 pixels.\n",
    "IMAGE_SIZE = 28\n",
    "\n",
    "# Each image is 28 X 28 in dimension. We flatten the image to get 784 features where each feature would correspond to one pixel.\n",
    "IMAGE_PIXELS = IMAGE_SIZE * IMAGE_SIZE\n",
    "\n",
    "# Batch size \n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# Defining the number of units in hidden layers\n",
    "HIDDEN_LAYER_1 = 50\n",
    "HIDDEN_LAYER_2 = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Letting the tensorflow know that our inputs will contain real values only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=IMAGE_PIXELS)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our classifier. Remember those three steps. Here is it for your reference again.\n",
    "\n",
    "![The three steps](media/Steps.jpg)\n",
    "\n",
    "### Luckily for us, 'tf.contrib.learn.DNNClassifier' takes care of all these three steps by itself. Yay again!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0f6e898048>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './model_data'}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                              hidden_units=[HIDDEN_LAYER_1, HIDDEN_LAYER_2],\n",
    "                                              n_classes=NUM_CLASSES,\n",
    "                                              model_dir=\"./model_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating functions to feed data to our 'DNNClassifier'. Remember that it accepts inputs in a particular fashion only. This is the best acceptable way of doing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the training inputs\n",
    "def get_train_inputs():\n",
    "    batch = mnist.train.next_batch(BATCH_SIZE)\n",
    "    x = tf.constant(batch[0])\n",
    "    y = tf.constant(batch[1], tf.int64)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "# Define the test inputs\n",
    "def get_test_inputs():\n",
    "    x = tf.constant(mnist.test.images)\n",
    "    y = tf.constant(mnist.test.labels, tf.int64)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ..., 3, 2, 1. Here goes our training......... Pay attention to the value just next to the tag 'loss'. It should ideally keep on decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sanjay/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:642: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./model_data/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.32303, step = 1\n",
      "INFO:tensorflow:global_step/sec: 439.184\n",
      "INFO:tensorflow:loss = 0.030953, step = 101 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.305\n",
      "INFO:tensorflow:loss = 0.00908973, step = 201 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.697\n",
      "INFO:tensorflow:loss = 0.00488031, step = 301 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.806\n",
      "INFO:tensorflow:loss = 0.00321573, step = 401 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.208\n",
      "INFO:tensorflow:loss = 0.00235622, step = 501 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.058\n",
      "INFO:tensorflow:loss = 0.00184017, step = 601 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.976\n",
      "INFO:tensorflow:loss = 0.00149891, step = 701 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.568\n",
      "INFO:tensorflow:loss = 0.00125817, step = 801 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.246\n",
      "INFO:tensorflow:loss = 0.00108022, step = 901 (0.213 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ./model_data/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000944836.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x7f0f6e88aef0>, 'hidden_units': [50, 20], 'feature_columns': (_RealValuedColumn(column_name='', dimension=784, default_value=None, dtype=tf.float32, normalizer=None),), 'optimizer': None, 'activation_fn': <function relu at 0x7f0f6ee118c8>, 'dropout': None, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model.\n",
    "classifier.fit(input_fn=get_train_inputs, steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating our model on test inputs. We got decent results in very quick time, didn't we? Hurrah!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sanjay/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:642: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-24-20:51:28\n",
      "INFO:tensorflow:Restoring parameters from ./model_data/model.ckpt-12000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-24-20:51:29\n",
      "INFO:tensorflow:Saving dict for global step 12000: accuracy = 0.8567, global_step = 12000, loss = 0.818702\n",
      "\n",
      "Test Accuracy: 0.856700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy.\n",
    "accuracy_score = classifier.evaluate(input_fn=get_test_inputs, steps=1)[\"accuracy\"]\n",
    "\n",
    "print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That was not too hard. But is this enough or do we need to know more? The answer is both yes and no, depending on what we want do you want to do with your deep learning model. Let's switch back to the slides."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
